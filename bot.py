# √âtape 1 : Importer les biblioth√®ques dont on a besoin
import os
import requests
from bs4 import BeautifulSoup
import time
import random
from supabase import create_client, Client 

# √âtape 2 : Configurer nos variables
DEALABS_URL = "https://www.dealabs.com/hot"

# ATTENTION : J'ai masqu√© votre webhook Discord pour la s√©curit√©
# Remplacez par votre vraie URL de webhook
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "https://discordapp.com/api/webhooks/1406262114183807146/BHrmH-9KbJfd-e6bHz9ScTnS7VuwL7NDnlArqWxoE86IO4RGiArnT9oOy5v0Mu4WPq2x")

# NOUVEAUX PARAM√àTRES DE FILTRAGE
TEMPERATURE_MINIMUM = 100  # Temp√©rature minimum pour envoyer un deal
TEMPERATURE_PREMIUM = 500  # Temp√©rature pour les deals "premium"
TEMPERATURE_HOT = 1000     # Temp√©rature pour les deals "tr√®s hot"

# Headers plus r√©alistes pour √©viter la d√©tection
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
    'Referer': 'https://www.google.com/'
}

def scraper_dealabs():
    """
    Version am√©lior√©e du scraper avec plusieurs s√©lecteurs CSS pour s'adapter 
    aux changements de structure du site
    """
    print("üîç Tentative de scraping de Dealabs...")
    
    try:
        # Ajouter un d√©lai al√©atoire pour para√Ætre plus humain
        time.sleep(random.uniform(1, 3))
        
        session = requests.Session()
        session.headers.update(HEADERS)
        
        response = session.get(DEALABS_URL, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Essayer diff√©rents s√©lecteurs CSS possibles
        selectors_to_try = [
            # S√©lecteurs r√©cents possibles
            'article[class*="thread"]',
            'div[class*="thread"]',
            'article[data-thread-id]',
            'div[data-thread-id]',
            # Anciens s√©lecteurs
            'article.thread--card',
            'div.thread--card',
            # S√©lecteurs g√©n√©riques
            'article',
            'div[class*="deal"]',
            'div[class*="offer"]'
        ]
        
        all_deals = []
        
        for selector in selectors_to_try:
            all_deals = soup.select(selector)
            if all_deals:
                print(f"‚úÖ Trouv√© {len(all_deals)} √©l√©ments avec le s√©lecteur: {selector}")
                break
        
        if not all_deals:
            print("‚ùå Aucun √©l√©ment trouv√© avec les s√©lecteurs CSS")
            # Debug: afficher un √©chantillon du HTML
            print("üìÑ Voici un √©chantillon du HTML re√ßu:")
            print(soup.prettify()[:1000] + "...")
            return None, None
        
        # Essayer de trouver les liens et titres dans les √©l√©ments trouv√©s
        for i, deal_element in enumerate(all_deals[:20]):  # Augment√© √† 20 pour plus de chances
            print(f"üîç Analyse de l'√©l√©ment {i+1}...")
            
            # √âTAPE 1 : EXTRACTION DE LA TEMP√âRATURE
            temperature = extraire_temperature(deal_element)
            print(f"üå°Ô∏è Temp√©rature d√©tect√©e : {temperature}¬∞")
            
            # FILTRAGE : On ignore les deals en dessous du seuil
            if temperature < TEMPERATURE_MINIMUM:
                print(f"‚ùÑÔ∏è Deal ignor√© (temp√©rature {temperature}¬∞ < {TEMPERATURE_MINIMUM}¬∞)")
                continue
            
            # √âTAPE 2 : EXTRACTION DU LIEN
            # Diff√©rentes fa√ßons de chercher le lien
            link_selectors = [
                'a[class*="thread-link"]',
                'a[href*="/deals/"]',
                'a[href*="/bons-plans/"]',
                'a[title]',
                'a'
            ]
            
            link_tag = None
            for link_selector in link_selectors:
                link_tag = deal_element.select_one(link_selector)
                if link_tag and 'href' in link_tag.attrs:
                    break
            
            if not link_tag:
                print("‚ùå Aucun lien trouv√© dans cet √©l√©ment")
                continue
            
            # √âTAPE 3 : EXTRACTION DU TITRE
            # Diff√©rentes fa√ßons de chercher le titre
            title_selectors = [
                'strong',
                'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
                '[class*="title"]',
                '[class*="heading"]',
                'span'
            ]
            
            title_text = None
            for title_selector in title_selectors:
                title_element = link_tag.select_one(title_selector)
                if title_element:
                    title_text = title_element.get_text(strip=True)
                    if title_text and len(title_text) > 10:  # Titre valide
                        break
            
            # Fallback: utiliser le texte du lien ou l'attribut title
            if not title_text:
                title_text = link_tag.get('title', '').strip()
                if not title_text:
                    title_text = link_tag.get_text(strip=True)
            
            # √âTAPE 4 : VALIDATION ET RETOUR
            if title_text and len(title_text) > 5:
                deal_link = link_tag['href']
                
                # Construire l'URL compl√®te si n√©cessaire
                if not deal_link.startswith('http'):
                    deal_link = "https://www.dealabs.com" + deal_link
                
                # √âmoji en fonction de la temp√©rature
                temp_emoji = get_temperature_emoji(temperature)
                
                print(f"‚úÖ Deal {temp_emoji} trouv√© ({temperature}¬∞) : {title_text[:80]}{'...' if len(title_text) > 80 else ''}")
                return title_text, deal_link, temperature
        
        print("‚ùå Aucun deal valide trouv√© dans les √©l√©ments analys√©s")
        return None, None, 0
        
    except requests.exceptions.Timeout:
        print("‚è∞ Timeout lors de la connexion √† Dealabs")
        return None, None, 0
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur lors de la requ√™te √† Dealabs : {e}")
        return None, None, 0
    except Exception as e:
        print(f"‚ùå Erreur inattendue : {e}")
        return None, None, 0

def extraire_temperature(deal_element):
    """
    Extrait la temp√©rature d'un √©l√©ment de deal.
    Retourne 0 si aucune temp√©rature n'est trouv√©e.
    """
    # S√©lecteurs possibles pour la temp√©rature
    temp_selectors = [
        # S√©lecteurs sp√©cifiques √† la temp√©rature
        '[class*="temperature"]',
        '[class*="temp"]',
        '[class*="vote"]',
        '[class*="score"]',
        '[class*="rating"]',
        # S√©lecteurs plus g√©n√©riques
        'span[title*="¬∞"]',
        'div[title*="¬∞"]',
        'span[class*="number"]',
        # Recherche dans le texte
        '*'
    ]
    
    for selector in temp_selectors:
        try:
            elements = deal_element.select(selector)
            for element in elements:
                # Chercher dans le texte de l'√©l√©ment
                text = element.get_text(strip=True)
                temperature = extraire_nombre_temperature(text)
                if temperature > 0:
                    return temperature
                
                # Chercher dans les attributs title, data-*, etc.
                for attr_name, attr_value in element.attrs.items():
                    if isinstance(attr_value, str):
                        temperature = extraire_nombre_temperature(attr_value)
                        if temperature > 0:
                            return temperature
        except:
            continue
    
    return 0

def extraire_nombre_temperature(text):
    """
    Extrait un nombre de temp√©rature d'un texte.
    Exemples: "125¬∞" -> 125, "+89" -> 89, "temp√©rature: 234" -> 234
    """
    import re
    
    # Patterns pour trouver des nombres li√©s √† la temp√©rature
    patterns = [
        r'(\d+)¬∞',           # Format: 123¬∞
        r'(\d+)\s*¬∞',        # Format: 123 ¬∞
        r'\+(\d+)',          # Format: +123
        r'-(\d+)',           # Format: -123 (temp√©rature n√©gative)
        r'(\d+)\s*points?',  # Format: 123 points
        r'(\d+)\s*votes?',   # Format: 123 votes
        r'(\d{2,4})',        # Nombres de 2 √† 4 chiffres (probable temp√©rature)
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        if matches:
            try:
                # Prendre le plus grand nombre trouv√© (souvent la temp√©rature)
                numbers = [int(match) for match in matches]
                # Filtrer les nombres qui semblent √™tre des temp√©ratures (entre 1 et 9999)
                valid_temps = [n for n in numbers if 1 <= n <= 9999]
                if valid_temps:
                    return max(valid_temps)
            except ValueError:
                continue
    
    return 0

def get_temperature_emoji(temperature):
    """
    Retourne un √©moji en fonction de la temp√©rature du deal
    """
    if temperature >= TEMPERATURE_HOT:
        return "üî•üî•üî•"
    elif temperature >= TEMPERATURE_PREMIUM:
        return "üî•üî•"
    elif temperature >= TEMPERATURE_MINIMUM:
        return "üî•"
    else:
        return "‚ùÑÔ∏è"

def envoyer_notification_discord(titre, lien, temperature=0):
    """
    Envoie une notification Discord avec une meilleure mise en forme
    et des informations sur la temp√©rature
    """
    # Limiter la longueur du titre pour Discord
    if len(titre) > 180:  # R√©duit pour faire place √† la temp√©rature
        titre = titre[:177] + "..."
    
    # √âmoji et formatage en fonction de la temp√©rature
    temp_emoji = get_temperature_emoji(temperature)
    temp_text = f" ({temperature}¬∞)" if temperature > 0 else ""
    
    # Message personnalis√© selon la temp√©rature
    if temperature >= TEMPERATURE_HOT:
        intro = f"üö® **DEAL TR√àS HOT D√âTECT√â !** {temp_emoji}"
    elif temperature >= TEMPERATURE_PREMIUM:
        intro = f"üî• **EXCELLENT DEAL D√âTECT√â !** {temp_emoji}"
    else:
        intro = f"‚ú® **Nouveau Deal D√©tect√© !** {temp_emoji}"
    
    message_pour_discord = f"{intro}\n\n**{titre}**{temp_text}\n\nüîó **Lien :** {lien}"
    
    data = {
        "content": message_pour_discord,
        "username": "DealBot",
        "avatar_url": "https://cdn-icons-png.flaticon.com/512/3159/3159310.png"
    }

    print("üì§ Envoi de la notification √† Discord...")
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=10)
        response.raise_for_status()
        print("‚úÖ Notification envoy√©e avec succ√®s !")
        return True
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur lors de l'envoi √† Discord : {e}")
        return False

def debug_page_structure():
    """
    Fonction de debug pour analyser la structure de la page
    """
    print("üîç Mode debug - Analyse de la structure de la page...")
    
    try:
        session = requests.Session()
        session.headers.update(HEADERS)
        
        response = session.get(DEALABS_URL, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print("üìä Analyse des √©l√©ments trouv√©s sur la page:")
        
        # Chercher tous les liens
        all_links = soup.find_all('a', href=True)
        deal_links = [link for link in all_links if any(keyword in link['href'].lower() for keyword in ['/deals/', '/bons-plans/', '/groupe/'])]
        
        print(f"üîó Nombre total de liens: {len(all_links)}")
        print(f"üéØ Liens potentiels de deals: {len(deal_links)}")
        
        if deal_links:
            print("üìã Premiers liens de deals trouv√©s:")
            for i, link in enumerate(deal_links[:5]):
                title = link.get_text(strip=True)[:100]
                href = link['href']
                print(f"  {i+1}. {title} -> {href}")
        
        # Analyser les classes CSS communes
        all_elements_with_class = soup.find_all(attrs={"class": True})
        class_counts = {}
        for elem in all_elements_with_class[:100]:  # Limiter pour √©viter la surcharge
            for class_name in elem.get('class', []):
                if 'thread' in class_name.lower() or 'deal' in class_name.lower():
                    class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        if class_counts:
            print("üè∑Ô∏è  Classes CSS int√©ressantes trouv√©es:")
            for class_name, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"  .{class_name} ({count} fois)")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du debug : {e}")

# --- LE PROGRAMME PRINCIPAL - VERSION SUPABASE ---
if __name__ == "__main__":
    print("ü§ñ D√©marrage du bot Dealabs...")

    # --- NOUVELLE PARTIE : CONNEXION √Ä SUPABASE ---
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")
    
    # V√©rifie si les secrets sont bien configur√©s
    if not supabase_url or not supabase_key:
        print("‚ùå ERREUR: Les secrets SUPABASE_URL et SUPABASE_KEY ne sont pas configur√©s.")
        exit(1)
        
    supabase: Client = create_client(supabase_url, supabase_key)
    print("‚úÖ Connect√© √† la base de donn√©es Supabase.")

    titre_du_deal, lien_du_deal, temperature_du_deal = scraper_dealabs()

    if titre_du_deal and lien_du_deal:
        # V√©rifier si le lien existe d√©j√† dans la base de donn√©es
        response = supabase.table('deals_envoyes').select('id').eq('deal_link', lien_du_deal).execute()
        
        # Si la r√©ponse contient des donn√©es, c'est qu'on l'a d√©j√† envoy√©
        if len(response.data) == 0:
            print(f"‚ú® Nouveau deal trouv√© ! Envoi en cours...")
            success = envoyer_notification_discord(titre_du_deal, lien_du_deal, temperature_du_deal)
            
            if success:
                # Ins√©rer le nouveau lien dans la table Supabase
                supabase.table('deals_envoyes').insert({"deal_link": lien_du_deal}).execute()
                print("üíæ Deal sauvegard√© dans la base de donn√©es.")
                print("üéâ Mission accomplie !")
            else:
                print("‚ö†Ô∏è  Deal trouv√© mais erreur lors de l'envoi √† Discord.")
        else:
            print(f"ü•± Ce deal a d√©j√† √©t√© envoy√© (trouv√© en BDD). On l'ignore.")
    else:
        print("‚ùå Aucun deal √† envoyer.")
        print(f"üí° Seuil de temp√©rature actuel : {TEMPERATURE_MINIMUM}¬∞")
        print("\nüîß Suggestions:")
        print("   1. R√©duisez TEMPERATURE_MINIMUM pour des deals moins populaires")
        print("   2. D√©commentez debug_page_structure() pour analyser la page.")
        print("   3. V√©rifiez que le site n'a pas chang√© de structure.")
        print("   4. Essayez √† nouveau dans quelques minutes.")